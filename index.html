<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Siliang Zeng</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Siliang Zeng</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpeg" alt="" width="200px" />&nbsp;</td>
<td align="left"><p><br /> <a href="https://cse.umn.edu/ece">Electrical and Computer Engineering</a>, <br />
<a href="https://twin-cities.umn.edu/">University of Minnesota, Twin Cities</a><br />
<a href="https://scholar.google.com/citations?user=IfqsDyYAAAAJ&amp;hl=en">Google Scholar</a>, <a href="https://www.dropbox.com/s/acijvy7gkjlnzo5/Siliang%20CV%202022.10.pdf?dl=0">CV</a> <br />
Email: zeng0176 <a href="at">at</a> umn (dot) edu</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a third year PhD student at <a href="https://twin-cities.umn.edu/">University of Minnesota</a>, advised by <a href="https://people.ece.umn.edu/~mhong/mingyi.html">Prof. Mingyi Hong</a>. <br />
Before moving to Minnesota, I received the B.S. in Statistics from <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a> in 2020. <br /></p>
<p>In my research, I am always thinking about how to design practical algorithms and systems for sequential decision making under uncertainty. <br />
My recent research topics include inverse reinforcement learning, imitation learning and offline reinforcement learning.
<br /></p>
<h2>Representative / Recent Works</h2>
<ul>
<li><p><a href="http://arxiv.org/abs/2210.01282">Structural Estimation of Markov Decision Processes in High-Dimensional
State Space with Finite-Time Guarantees</a> <br /> 
<b>Siliang Zeng</b>, Mingyi Hong, Alfredo Garcia <br />
Submitted Journal Paper, 2022 <br /></p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2210.01808">Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees</a> <br /> 
<b>Siliang Zeng</b>, Chenliang Li, Alfredo Garcia, Mingyi Hong <br />
Thirty-sixth Conference on Neural Information Processing Systems (<b>NeurIPS 2022</b>). <br />
(A previous version accepted by Decision Awareness in Reinforcement Learning Workshop at ICML 2022) </p>
</li>
</ul>
<h2>Recent News</h2>
<ul>
<li><p>Oct 2022:: I am thrilled to receive the <b>NeurIPS 2022 Scholar Award</b>. See you in New Orleans!</p>
</li>
</ul>
<ul>
<li><p>Sep 2022: Two papers have been accepted to <b>NeurIPS 2022</b>: <br />
<a href="http://arxiv.org/abs/2210.01808">Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees.</a> <br />
<a href="http://arxiv.org/abs/2210.01808">A Stochastic Linearized Augmented Lagrangian Method for Decentralized Bilevel Optimization.</a> <br />




</p>
</li>
</ul>
<ul>
<li><p>Jul 2022: I have been selected for a travel grant from the DARL Workshop at ICML 2022! 
</p>
</li>
</ul>
<ul>
<li><p>Jun 2022: One paper has been accepted to <b>Decision Awareness in Reinforcement Learning Workshop at ICML 2022</b>: <a href="https://openreview.net/forum?id=FfELl5h3Nec"><br /> Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees</a>. <br />




</p>
</li>
</ul>
<ul>
<li><p>Jun 2022: One paper has been accepted to <b>SIAM Journal on Optimization</b>: <a href="https://arxiv.org/abs/2006.11662"><br /> On the Divergence of Decentralized Non-Convex Optimization</a>. <br />



</p>
</li>
</ul>
<ul>
<li><p>Mar 2022: One paper has been accepted to <b>L4DC 2022</b>: <a href="https://arxiv.org/abs/2110.05597"><br /> Learning to Coordinate in Multi-Agent Systems: A Coordinated Actor-Critic Algorithm and Finite-Time Guarantees</a>. <br />




</p>
</li>
</ul>
<ul>
<li><p>Sep 2021: One paper has been accepted to <b>NeurIPS 2021</b>: <a href="https://arxiv.org/abs/2102.07367"><br /> A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum</a>. <br />


</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
